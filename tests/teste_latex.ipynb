{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5red1qiheBm1Hnz1UeOFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isa-ulisboa/greends-pml/blob/main/tests/teste_latex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Course on Pratical Machine Learning\n",
        "\n",
        "Masters in Green Data Science, ISA/ULisboa, 2022-2023\n",
        "\n",
        "Instructor: Manuel Campagnolo mlc@isa.ulisboa.pt"
      ],
      "metadata": {
        "id": "f0qoqpJ4-iom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction and some basic concepts in Machine Learning (ML)\n",
        "\n",
        "In this course we are dealing with data that are *labeled examples*. Examples can be scalar numbers, rows of tabular data, images, etc. For tabular data, we refer the to columns as *explanatory variables* (sometimes also called *independent variables*).\n",
        "\n",
        "Labels can be categorial, ordinal or continuous. Typically, we the problems are called:\n",
        "1. *Regression problems*, when the labels are continuous. \n",
        "2. *Classification problems*, when the labels are categorial.\n",
        "\n",
        "The distinction is not always clear. Some problems can be considered either as regression or classification problems. \n",
        "\n",
        "Given a ML problem, that is a set of labeled examples, the goal is to build a so-called *model* (which is simply a function $f$) that maps examples to labels, or in other words, that predicts the label from the example.\n",
        "\n",
        "## Models and parameters\n",
        "\n",
        "Let $ùö¨$ by the set of examples and $L$ a set that includes the labels, then $$f_\\wbfw: E ‚Üí L$$. \n"
      ],
      "metadata": {
        "id": "RP73ZCHW-5IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples + labels\n",
        "\n",
        "Examples cab be images, rows in tabular data, text...\n",
        "Labels can be categorial, ordinal or continuous\n",
        "\n",
        "If labels are continuous, the problem is typically a regression problem\n",
        "....\n",
        "\n",
        "Ml: map an example to the set of labels to predict the label from the example\n",
        "\n",
        "Ml is done through a function f_w: X to Y, where w are a set of parameters of the function.\n",
        "\n",
        "More conveniently the predicted label is given by, y=f(x;w)\n",
        "\n",
        "F can be a neural network, a CNN, a regression model, a decision tree, an ensemble of other models, et\n",
        "\n",
        "Loss  for a set of examples x1, x2, ... and a set of weights w, the loss l(w) is a new function that measures the dissimilarity between  predicted labels f(x1;w)... And the actual labels  y1,....\n",
        "\n",
        "Examples of loss functions\n",
        "For r√©gression\n",
        "For classification\n",
        "\n",
        "Ml as an optimization problem:\n",
        "Determine w to minimize loss\n",
        "\n",
        "In some very simple  cases the optimum can be determined analytacally. In general, it can be searched by heuristic methods.\n",
        "\n",
        "One of the heuristic methods is gradient descent that uses a learning rate.\n",
        "\n",
        "Examples\n",
        "1. Quadratic function\n",
        "Xs are just scalars\n",
        "Y are continuous (regression problem)\n",
        "F_w is f(x;a,b,c)\n",
        "Loss is m√£e or rmse\n",
        "In this case the best set of weights can be determined analytacally\n",
        "In alternative one can use gradient descent\n",
        "\n",
        "2. Perceptron (no sigmoid) = mlr\n",
        "X are vectors , after preprocessing\n",
        "Y are 0 or 1 (regression or classification)\n",
        "Fw is S(X1 w1+....)\n",
        "Loss is ...\n",
        "In this case the problem 8s equivalent to least square mlr, and has an analital solution\n",
        "\n",
        "3. Perceptron with sigmoid output\n",
        "\n",
        "\n",
        "4 FC nn with hidden layers"
      ],
      "metadata": {
        "id": "RfyfFm1F-fdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{align}\n",
        "        \\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^n a_i b_i.\n",
        "    \\end{align}\n"
      ],
      "metadata": {
        "id": "2z58e_5aNSgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9rS-hWpR-ea-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dWUVyJdNRvE"
      },
      "outputs": [],
      "source": []
    }
  ]
}